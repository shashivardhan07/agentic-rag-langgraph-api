# ğŸ¤– Agentic RAG API using LangGraph, LangChain & FastAPI

An **Agentic Retrieval-Augmented Generation (RAG)** system built using **LangGraph** and **LangChain**, exposed as an **API** using **FastAPI / Flask**.  
This project demonstrates how multiple LLM-powered agents can **collaborate, reason, retrieve, evaluate, and generate answers** in a structured graph-based workflow.

---

## ğŸš€ Features

- Agentic RAG architecture using LangGraph
- Modular LLM agents with clear responsibilities
- Dynamic query rewriting and routing
- Document retrieval using vector databases
- Answer generation with evaluation and grading
- API-based interface (FastAPI / Flask)
- Clean, production-ready project structure

---

## ğŸ§  Agentic Workflow

The system uses **multiple agents**, each responsible for a specific task:

1. **Query Agent** â€“ understands or reformulates user queries  
2. **Retrieval Agent** â€“ fetches relevant documents from the vector store  
3. **Grader Agent** â€“ evaluates retrieved documents for relevance  
4. **Rewrite Agent** â€“ improves the query if retrieval quality is low  
5. **Answer Agent** â€“ generates the final answer using the LLM  
6. **Graph Builder** â€“ orchestrates the agents using LangGraph  

This loop continues until a high-quality answer is produced.

---

## ğŸ“‚ Project Structure

<pre>
agentic-rag-langgraph-api/
â”œâ”€â”€ app.py                  # API entry point (Flask / FastAPI)
â”œâ”€â”€ graph_builder.py        # LangGraph workflow definition
â”œâ”€â”€ llm_client.py           # LLM configuration and client
â”œâ”€â”€ vectorstore.py          # Vector database setup
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ query_agent.py
â”‚   â”œâ”€â”€ retrieval_agent.py
â”‚   â”œâ”€â”€ grader_agent.py
â”‚   â”œâ”€â”€ rewrite_agent.py
â”‚   â””â”€â”€ answer_agent.py
</pre>

---

## ğŸ› ï¸ Tech Stack

- Python
- LangChain
- LangGraph
- FastAPI / Flask
- Vector Databases (FAISS / Pinecone)
- Large Language Models (Gemini / OpenAI / Groq)
- dotenv for environment management

---

## âš™ï¸ Environment Setup

Create a `.env` file using the template below:

LLM_API_KEY=your_llm_api_key

VECTOR_DB_API_KEY=your_vector_db_key

